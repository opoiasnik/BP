
\chapter{Úvod a cieľová skupina}
\sectionmark{Úvod a cieľová skupina}

Potrebnosť po spoľahlivých a jednoducho dostupných informáciách o liekoch bola nikdy taká dôležitá v oblasti farmaceutického priemyslu. S rýchlym pokrokom
v medicíne, obrovské množstvo dostupných údajov často komplikuje rýchly prístup k presným a relevantným informáciám.

\section{Motivácia a problém}
Zdravotnícki odborníci a pacienti
často vyžadujú podrobné informácie o liekoch, vrátane ich aplikácie, vedľajších
účinkov a možných interakcií. Avšak nájsť tieto informácie môže byť náročné
kvôli rozptýlenosti zdrojov, nekonzistentnej terminológii alebo občas zastaraným
údajom.
Pre lekárov a ďalších zdravotníckych pracovníkov je prístup k komplexným
a odborným informáciám nevyhnutný pre kvalifikované rozhodovanie. Pacienti,
naopak, potrebujú jasné a zrozumiteľné vysvetlenia, aby pochopili svoje možnosti
liečby. Bohužiaľ, existujúce riešenia často nedokážu splniť tieto rôznorodé potreby. Informácie môžu byť príliš technické pre bežnú verejnosť alebo nedostatočne
podrobné pre odborníkov.
V reakcii na tieto problemy tento projekt predstavuje systém odporúčaní založený na umelej inteligencii, ktorý rieši informačnú medzeru. Interpretáciou
dotazov v prirodzenom jazyku systém poskytuje dostupné odporúčania liekov.
Cieľom je vytvoriť riešenie, ktoré používateľom umožní klásť otázky v bežnom
jazyku a dostávať jasné a zrozumiteľné odpovede prispôsobené ich špecifickým
potrebám.

\section{Kto používa systém?}

\textbf{Lekári a zdravotnícki pracovníci:} Títo používatelia potrebujú rýchly prístup k prehľadným informáciám o liekoch, aby mohli rýchlo nájsť odporúčania, ktoré obsahujú názov lieku, krátke vysvetlenie a základné údaje, ako dávkovanie alebo čas užívania.\\
\textbf{Farmaceuti:} Pre farmaceutov je dôležité dostať podrobnejšie informácie, napríklad technické detaily a popisy interakcií medzi liekmi.\\
\textbf{Pacienti:} Systém by mal pomôcť pacientom získať jednoduché a zrozumiteľné odporúčania, aby vedeli, čo očakávať pri liečbe, bez príliš technického jazyka.\\
\textbf{Administratívni pracovníci a manažéri:} Títo používatelia využívajú systém na získavanie štatistík, sledovanie trendov a podporu rozhodovacích procesov.




\subsection{Očakávania používateľov a prínos systému}

Rôzne skupiny používateľov majú od systému rôzne očakávania. Napríklad, lekári potrebujú rýchle a stručné informácie, aby mohli okamžite reagovať v klinickej praxi. Farmaceuti chcú mať prístup k detailným technickým údajom o liekoch. Pacienti očakávajú jednoduché a jasné odporúčania, ktoré im pomôžu pochopiť, čo môžu očakávať od liečby, bez zložitého jazyka. Administratívni pracovníci a manažéri vyžadujú spoľahlivé prehľady a údaje, ktoré im pomôžu pri rozhodovaní.

Systém pomáha tým, že rýchlo vyhľadáva potrebné informácie a vytvára odpovede, ktoré sú prispôsobené potrebám každej skupiny. Týmto spôsobom dostanú všetci používatelia informácie, ktoré sú presne podľa ich očakávaní.

\subsection{Konkrétne požiadavky jednotlivých skupín}

Každá skupina má aj svoje špecifické požiadavky. Lekári potrebujú jednoduchý a prehľadný výstup, aby vedeli, ktoré lieky odporučiť. Farmaceuti vyžadujú podrobné údaje s technickými detailmi a informáciami o interakciách medzi liekmi. Pacienti chcú, aby odpovede boli písané jednoduchým a zrozumiteľným jazykom, bez príliš odborných výrazov. Administratívni pracovníci a manažéri očakávajú, že systém bezpečne spracováva citlivé informácie a poskytuje prehľadné štatistiky.

Týmto spôsobom systém zabezpečuje, že každý používateľ dostane odpovede prispôsobené jeho konkrétnym požiadavkám a pomáha zlepšiť rozhodovanie a prácu v zdravotníctve.







\chapter{Problematika a teoretické základy}

Hoci je dnes k dispozícii veľa informácií o liekoch, prístup k spoľahlivým a aktuálnym dátam predstavuje problém pre zdravotníckych pracovníkov, pacientov aj ďalších používateľov. Informácie o liekoch – napríklad o vedľajších účinkoch, kontraindikáciách či interakciách – sú často roztrúsené medzi rôzne zdroje, čo sťažuje ich rýchle a úplné získanie v kritických situáciách.\\
Medzi hlavné problémy patria:\\
\textbf{Roztrúsenosť dát:} Informácie o liekoch sú uložené na viacerých platformách, ako sú vedecké časopisy, databázy a príbalové letáky, pričom každý zdroj používa iný formát a terminológiu. To komplikuje rýchle vyhľadávanie a zostavovanie potrebných údajov.\\
    \textbf{Jazyková bariéra:} Technický jazyk, v ktorom sú informácie prezentované, môže byť pre pacientov a laikov ťažko zrozumiteľný. Zdravotnícki odborníci ovládajú odbornú terminológiu, ale pre širokú verejnosť je potrebná jednoduchšia a jasnejšia forma.\\
    \textbf{Obmedzené možnosti vyhľadávania:} Tradičné vyhľadávacie metódy založené na kľúčových slovách často nedokážu správne interpretovať dotazy v prirodzenom jazyku. To sťažuje nájdenie presných informácií, najmä pri komplexných otázkach o interakciách liekov a špecifických zdravotných stavoch.\\
Preto je navrhnutý AI-riadený odporúčací systém s využitím NLP, ktorý má zabezpečiť jednoduchší a presnejší prístup k farmaceutickým informáciám. Tento systém umožní používateľom rýchlo nájsť potrebné dáta a zároveň zlepší ich zrozumiteľnosť a spoľahlivosť.

\vspace{1em}

V tejto kapitole je uvedený prehľad teoretických myšlienok, ktoré sú základom riešenia. Cieľom je ukázať, bez toho, aby sa opakovali špecifiká technických kapitol, ako projekt využíva myšlienky generatívneho spracovania prirodzeného jazyka, sémantického vyhľadávania a štruktúrovaného spracovania údajov. Poskytnuté informácie umožňujú pochopiť návrhy jednotlivých častí a ich funkcie v rámci celého systému.

\section{História a evolúcia generatívnych jazykových modelov}
Vývoj generatívnych jazykových modelov prešiel v posledných desaťročiach dynamickým rozvojom. Prvé prístupy sa zakladali najmä na štatistických \emph{n-gram} modeloch, ktoré spracovávali text na úrovni slovných sekvencií bez hlbšej kontextovej väzby. Následne s nástupom neurónových sietí nastal prelom — modely typu RNN (Recurrent Neural Networks) umožnili lepšie zachytávať súvislosti v texte, hoci pri dlhších vetách narážali na problém \emph{exploding} či \emph{vanishing gradients}.
Zásadný posun priniesli architektúry založené na transformeroch, ktoré umožnili paralelné spracovanie a dlhodobejšie zachovanie kontextu. Modely ako GPT, BERT či T5 v sebe skombinovali rozsiahle predtrénovanie na obrovských korpusoch textu s možnosťou \emph{fine-tuningu} na špecifické úlohy. Tento prístup výborne škáluje s dostupným výpočtovým výkonom, čo viedlo k masívnemu zlepšeniu kvality generovaných textov \cite{15}.

\section{Generatívne modely a spracovanie prirodzeného jazyka}
Spracovanie prirodzeného jazyka (Natural Language Processing - NLP) je podoblasť umelej inteligencie, ktorá využíva počítačové modely a algoritmy na automatické porozumenie, analýzu a tvorbu ľudského jazyka.   Cieľom NLP je umožniť počítačom vyhodnocovať text a hlas podobným spôsobom ako ľudia.  Zahŕňa rôzne úlohy, napríklad analýzu nálad, preklad, extrakciu kľúčových slov a autonómnu syntézu textu.

Generatívne modely patria medzi metódy strojového učenia, ktoré sú navrhnuté na vytváranie nového textového obsahu na základe naučených jazykových štruktúr a vzorov. V teoretickom rámci sú tieto modely schopné analyzovať vstupný text a zachytiť jeho sémantické a syntaktické vlastnosti, generovať plynulé a kontextovo relevantné odpovede či texty a prispôsobiť výstup rôznym typom dopytov, pričom zachovávajú konzistenciu a logickú súdržnosť.


Základnou myšlienkou je, že model sa naučí štatistickú distribúciu jazykových prvkov a potom využije tieto znalosti na tvorbu nových, súvislých textových úsekov. Tento prístup umožňuje efektívne odpovedať na otázky a poskytovať odporúčania, pričom sa využíva adaptívne spracovanie vstupov. Moderné generatívne modely, ako napríklad GPT alebo ďalšie veľké jazykové modely, potvrdili Brown et al. \cite{15}, že sú schopné riešiť rôzne úlohy vrátane sumarizácie a prekladu s vysokou mierou presnosti.

\section{Kontextové modely a ich prínos}

V posledných rokoch sa ukázalo, že viacúrovňové kontextové modely dokážu spracovať text na viacerých úrovniach. To znamená, že systém pozerá na text z rôznych strán. Napríklad, jedna úroveň sa zameriava len na jednotlivé slová a ich gramatiku, zatiaľ čo iná sa snaží pochopiť, čo slová znamenajú v celej vete. Ďalšia úroveň berie do úvahy, v akom prostredí bol text napísaný, aby lepšie pochopila, čo autor myslel.

Na gramatickej úrovni model rozpozná základné jazykové jednotky, ako sú slová, čas, rod či pád. Na sémantickej úrovni potom priradí každému slovu alebo časti textu určitý význam (napríklad pomocou embeddingov) a sleduje, ako sú tieto časti navzájom prepojené. Nakoniec, na pragmatickej úrovni sa model pozrie aj na kontext, v ktorom bol text vytvorený, a na úmysel autora alebo na dlhodobú históriu konverzácie.

Tento prístup viacúrovňovej kontextualizácie je veľmi efektívny najmä v systémoch, ktoré vyžadujú precízne porozumenie textu, napríklad pri interpretácii medicínskych záznamov alebo pri personalizovanom odporúčaní liekov. Vďaka tomu môžu moderné jazykové modely detailnejšie pracovať s významom a správne reagovať na zložité dopyty, ktoré majú hlboký kontext alebo implicitné požiadavky.



\section{Vektorové vyhľadávanie a semantická analýza}
Semantické vyhľadávanie založené na vektorových reprezentáciách predstavuje metódu, pri ktorej sa textové dáta transformujú do vysokorozmerného priestoru. V teoretickom zmysle to znamená, že sémantické vlastnosti každého textového segmentu sú zachytené prostredníctvom číselného vektora, pričom vyhľadávacie algoritmy porovnávajú tieto vektory na meranie podobnosti medzi dotazmi a uloženými dokumentmi. Vďaka tomuto prístupu je možné nájsť relevantné informácie, aj keď sa jazyk dotazu výrazne líši od obsahu databázy.

\FloatBarrier
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{image1-2.png}
    \caption{Ilustrácia transformácie textu do vektorového priestoru.}
    \label{fig:vectorization}
\end{figure}
\FloatBarrier
Na rozdiel od konvenčných prístupov založených len na kľúčových slovách, zavedenie hustých vektorových reprezentácií (Dense Passage Retrieval) zvyšuje presnosť vyhľadávania, ako dokázali Karpukhin a kol. \cite{14}. Pri vyhľadávaní údajov z oblastí, kde môžu existovať nejednoznačnosti alebo rozdiely v terminológii, tento prístup umožňuje získať informácie na základe kontextu a sémantickej zhody.








\section{Spracovanie a normalizácia doménových dát}
Projekt využíva súbor údajov, ktorý obsahuje organizované informácie o drogách. Na zabezpečenie konzistentnosti a jednoduchého vyhľadávania sú údaje spracované a štandardizované. Okrem toho sú formátované tak, aby z nich bolo možné extrahovať relevantné údaje, ako je názov lieku, indikácie, vedľajšie účinky a interakcie. Okrem toho sa používajú reprezentácie kľúčových slov aj sémantických vektorov, aby sa materiál vhodne indexoval na účely kombinovaného vyhľadávania. Takto vytvorený súbor údajov zaručuje, že dodané informácie sú aktuálne, overené a dôkladné a zároveň poskytujú pevný základ na vytváranie odpovedí.



Teoretické základy tejto kapitoly ponúkajú široký rámec na pochopenie fungovania konštrukčného riešenia. Z nich jasne vyplýva, že medzi základné techniky patrí spracovanie doménových údajov na zaručenie konzistentnosti a kvality, vektorové vyhľadávanie na extrakciu sémanticky významných informácií a syntéza textu na základe naučených jazykových modelov. Tieto všeobecné usmernenia poskytujú pevný základ, na ktorom je založený následný prístup k projektu a jeho skutočná realizácia.



\chapter{Metodika a implementácia}
\label{chap:methodology_impl}

\section{Architektúra systému}

Jadrom projektu je odporúčací systém poháňaný umelou inteligenciou, navrhnutý na zjednodušenie prístupu k spoľahlivým farmaceutickým informáciám. Integráciou pokročilých technológií systém zabezpečuje presné načítavanie údajov a ponúka používateľsky prívetivú skúsenosť. Využíva spracovanie prirodzeného jazyka (NLP) a sofistikované vyhľadávacie funkcie na poskytovanie relevantných odporúčaní o liekoch na základe užívateľských dotazov. Pokročilé NLP techniky, založené na transformerovej architektúre, umožňujú systému nielen extrahovať kľúčové slová, ale aj zachytiť hlboké sémantické vzory a kontextuálne nuansy, čo vedie k lepšiemu pochopeniu zložitých dotazov \cite{8}.\\
Dôležitým prvkom v projekte je \textbf{Retrieval-Augmented Generation (RAG)}, ktorý spája vyhľadávanie relevantných dokumentov s generatívnym modelom.
\FloatBarrier % zabezpečí, že všetky predchádzajúce float objekty sa umiestnia pred týmto príkazom

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{rag.png}
    \caption{Schéma RAG.}
    \label{fig:rag_diagram}
\end{figure}

\FloatBarrier

Ako uvádza Lewis et al. \cite{13}, RAG umožňuje modelu pristupovať k externým znalostným zdrojom a následne vytvárať kontextovo bohatšie odpovede.

\section{Návrh frontendu a backendu}

Systém je vytvorený pomocou kombinácie backendových a frontendových technológií. Pri návrhu boli použité moderné trendy vo vývoji užívateľského rozhrania. Napríklad, pre flexibilné a rýchle štýlovanie bol inšpirovaný prístup utility-first CSS, ktorý detailne porovnáva Nguyen et al. \cite{6}. Pre analýzu moderných frontend frameworkov a efektívnu implementáciu komponentovo orientovaného prístupu boli čerpané poznatky z práce Garcia a Lee \cite{5}.\\
\textbf{Python}: \\Backend je implementovaný v Pythone, čo umožňuje jednoduchú integráciu rôznych knižníc a API, čím sa zefektívňuje vývoj dátových a NLP aplikácií \cite{1}.\\
\textbf{Elasticsearch}:\\ Na ukladanie a rýchle vyhľadávanie dokumentov je využitý Elasticsearch, ktorý vďaka inverznému indexovaniu a distribuovanej architektúre zabezpečuje efektívne spracovanie dotazov \cite{2}.\\
\textbf{Mistral jazykové modely}:\\ Na generovanie textov je použitá vlastná implementácia prístupu k Mistral API, ktorá umožňuje spracovať prirodzený jazyk a poskytnúť kontextovo citlivé odpovede.\\
\textbf{Hugging Face Embeddings}:\\ Táto knižnica poskytuje predtrénované modely pre generovanie textových embeddings, čo umožňuje sémantické vyhľadávanie a analýzu dokumentov.\\
\textbf{LangChain}:\\ Na tvorbu reťazených NLP operácií a integráciu modulov pre spracovanie textu, vyhľadávanie a generovanie odpovedí je použitý framework LangChain.

\section{Spracovanie údajov a výber modelu}

Efektívne spracovanie údajov a vhodný výber modelu sú kľúčové na poskytovanie presných a relevantných farmaceutických informácií, pretože spoľahlivá extrakcia a analýza dát umožňujú identifikovať najdôležitejšie informácie aj z rozsiahlych a heterogénnych zdrojov. Pri výbere modelov a optimalizácii techník spracovania údajov sa brali do úvahy aj novinky v oblasti NLP pre zdravotníctvo, ako sú prezentované v práci Lee et al. \cite{12}.

\subsection*{Spracovanie údajov}

Systém využíva Elasticsearch v kombinácii s Hugging Face embeddings na efektívnu prácu s údajmi. 
Farmaceutické údaje – vrátane podrobných popisov liekov, ich indikácií, vedľajších účinkov a interakcií – sú systematicky indexované tak, aby bolo možné využiť nielen tradičné textové vyhľadávanie, ale aj pokročilé sémantické vektorové vyhľadávanie. Táto hybridná metóda, o ktorej podrobne píše Manning et al. \cite{2}, umožňuje nielen vyhľadávanie na základe presných kľúčových slov, ale aj porovnávanie významov, čím sa výrazne zlepšuje relevantnosť výsledkov.

\subsection*{Výber modelu}
Pre generovanie textových embeddings sa využíva model \textit{\seqsplit{sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2}}. Tento model poskytuje multilingválnu reprezentáciu textových údajov, čo zlepšuje presnosť sémantického vyhľadávania a umožňuje efektívne porovnávanie textov v rôznych jazykoch.

Sentence-transformers predstavujú rodinu modelov, ktoré sú navrhnuté na generovanie semanticky významných embeddingov pre celé vety či textové úseky. Tieto modely sú postavené na základných architektúrach, ako je BERT. Cieľom je, aby semanticky podobné vety boli zobrazené ako podobné vektorové reprezentácie, čo zlepšuje výkon úloh ako sémantické vyhľadávanie, klastrovanie a identifikácia parafráz. Napríklad, Reimers a Gurevych \cite{16} demonštrovali účinnosť modelu Sentence-BERT na viacerých benchmarkoch, čím potvrdzujú robustnosť tohto prístupu.

Na porozumenie prirodzeného jazyka a generovanie odpovedí systém integruje Mistral jazykové modely prostredníctvom príslušného API. Výber konkrétneho modelu je založený na analýze výkonnostných kritérií, pričom sa zohľadňuje zložitosť používateľského dotazu. Transformery, ako uvádza Wolf et al. \cite{3}, excelujú v extrakcii kontextuálnych informácií, čo výrazne zvyšuje presnosť generovaných odpovedí. Navyše, implementácia mechanizmov na hodnotenie kvality odpovedí, popísaná v práci Wei et al. \cite{4}, umožňuje dynamicky optimalizovať výber modelu podľa komplexnosti dotazu. Tento prístup zabezpečuje, že jednoduché dotazy sú spracované rýchlejšie, zatiaľ čo zložité dotazy využívajú robustnejšie modely pre hlbšiu analýzu a generovanie detailnejších odpovedí.


\section{ Generovanie jazyka s podporou
vyhľadávania}
V praktickej implementácii sa princípy generatívneho spracovania prirodzeného jazyka, vektorového vyhľadávania a spracovania doménových údajov spájajú do jedného celku. Koncepčne možno celý proces opísať takto:
\begin{enumerate}
    \item Používateľ zadá dotaz formulovaný v prirodzenom jazyku.
    \item Systém spracuje dotaz a vykoná vyhľadávanie v dátach pomocou kombinácie tradičných a vektorových metód, čím získava relevantné informácie.
    \item Na základe zvolených údajov je zostavený dynamický prompt, ktorý poskytuje dostatočný kontext pre generatívny model.
    \item Generatívny model vytvorí odpoveď, ktorá je následne vyhodnotená a validovaná, aby bola zabezpečená jej úplnosť a logická konzistencia.
\end{enumerate}
\FloatBarrier
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{Schema.png}
    \caption{Schéma interakcie medzi vyhľadávaním (textovým aj vektorovým) a modelmi Mistral.}
    \label{fig:vectorization}
\end{figure}
\FloatBarrier

Na obrázku je znázornený postup spracovania požiadavky: dotaz používateľa je odoslaný na backend, systém vykoná paralelne textové vyhľadávanie (Elasticsearch) a vektorové vyhľadávanie pomocou MiniLM embeddings, výsledky vyhľadávania sa následne odovzdajú dvom jazykovým modelom Mistral – menšiemu \emph{(Mistral Small)} a väčšiemu \emph{(Mistral Large)}, a podľa zložitosti dotazu, jeho kontextu a hodnotenia kvality odpovedí sa vyberie najvhodnejší výstup.


Táto metóda umožňuje generovať odpovede bohaté na kontext, pretože model zohľadňuje dotaz aj údaje získané z databázy. Kombinácia adaptívneho generovania textu a sémantického vyhľadávania umožňuje získať presnejšiu a precíznejšiu odpoveď. To umožňuje efektívne spracovať zložité dotazy pomocou adaptívneho generovania textu a sémantickej analýzy.
\section{Stratégia nasadenia}

Na nasadenie aplikácie v rôznych prostrediach sa využíva Docker – open-source platforma, ktorá umožňuje zabaliť aplikáciu so všetkými jej závislosťami do jedného kontajnera. Kontajnery bežia v izolovanom prostredí, takže aplikácia funguje rovnako, nech je nasadená kdekoľvek. Hlavné výhody použitia Dockeru zahŕňajú prenositeľnosť, škálovateľnosť, izoláciu a jednoduché nasadenie. Prenositeľnosť znamená, že kontajnery nie sú viazané na konkrétny operačný systém, čo umožňuje jednoduchú migráciu aplikácie medzi rôznymi prostrediami a cloudovými platformami. Škálovateľnosť zabezpečuje rýchle spustenie viacerých identických kontajnerov, čo zaisťuje, že aplikácia dokáže zvládnuť vysoké zaťaženie. Izolácia je dosiahnutá tým, že každý kontajner beží nezávisle, čím sa minimalizujú konflikty medzi rôznymi aplikáciami a ich knižnicami. Jednoduché nasadenie je umožnené pomocou Docker Compose, ktorý umožňuje definovať viacero kontajnerov a ich vzájomné závislosti v jednom súbore, čím sa celý proces nasadenia výrazne zjednodušuje.

Implementačný proces pomocou Dockeru zahŕňa nasledujúce kroky. Najprv sa vytvorí Dockerfile, v ktorom sú definované inštrukcie na vytvorenie obrazu aplikácie, vrátane inštalácie potrebných balíkov, kopírovania zdrojového kódu a nastavenia konfiguračných premenných. Následne sa príkazom \texttt{docker build} vytvorí obraz, ktorý obsahuje všetky potrebné komponenty pre beh aplikácie. Po vytvorení obrazu sa príkazom \texttt{docker run} spustí kontajner, čím sa vytvorí izolované prostredie pre aplikáciu. Pre nasadenie viacerých kontajnerov a správu komplexných aplikácií sa využívajú nástroje ako Docker Compose, ktoré umožňujú automatizovanú orchestráciu a škálovanie podľa aktuálnych potrieb.

Podľa Boettigera \cite{9} Docker prináša nielen technické výhody, ale aj výrazné zjednodušenie vývojových a nasadzovacích postupov, čo vedie k rýchlejšej implementácii a zvýšeniu konzistencie medzi vývojovým a produkčným prostredím. Merk \cite{7} ďalej zdôrazňuje, že využitie Dockeru minimalizuje riziká spojené s konfiguráciami a zabezpečuje, že aplikácia bude fungovať rovnako na každom hostiteľskom systéme.

Táto stratégia vytvára pevný základ pre kontinuálnu integráciu a flexibilné nasadenie aplikácie v rôznych prostrediach. Umožňuje rýchlu adaptáciu a jednoduchú údržbu systému. Rozšírením tejto stratégie do automatizácie testovania a nasadzovania je možné vytvoriť plne integrovaný CI/CD pipeline, ktorý zabezpečí, že každá zmena v kóde bude rýchlo otestovaná, zabalená a nasadená do produkcie. Tento prístup skracuje čas zavádzania nových funkcií a znižuje riziko chýb spôsobených rozdielmi medzi vývojovým a produkčným prostredím.

Vďaka kontajnerizácii sa dosiahne vysoká izolácia jednotlivých častí systému, čo minimalizuje konflikty medzi závislosťami a uľahčuje aktualizácie. Pri potrebe opravy alebo aktualizácie je možné reštartovať iba konkrétny kontajner, čo zvyšuje dostupnosť a spoľahlivosť celého systému.

Pre overenie výkonnosti kontajnerizovaných riešení boli zohľadnené aj štúdie, ktoré ukazujú, že kontajnerizácia výrazne zlepšuje škálovateľnosť a efektivitu, ako to demonštruje Kumar et al. \cite{10}.

Integrácia Dockeru do nasadzovacieho procesu umožňuje rýchle reakcie na spätnú väzbu od používateľov a rýchle zavádzanie nových funkcií. Automatizované monitorovacie nástroje sledujú výkon a dostupnosť aplikácie, čo umožňuje okamžité škálovanie alebo zásah v prípade potreby. Celkovo táto stratégia zabezpečuje, že aplikácia bude vždy dostupná, spoľahlivá a pripravená reagovať na meniace sa požiadavky trhu, čo prispieva k dlhodobej udržateľnosti a konkurencieschopnosti systému.


\section{Prehľad architektúry systému}

Architektúra systému je navrhnutá tak, aby jednoducho a efektívne spracovávala požiadavky používateľov. Systém je rozdelený do niekoľkých vzájomne prepojených modulov, ktoré zabezpečujú dynamické generovanie vstupných údajov pre jazykový model, vyhľadávanie relevantných dokumentov, generovanie textu prostredníctvom externého rozhrania a následnú validáciu výsledkov. Jedna časť systému je zodpovedná za generovanie štruktúrovaných vstupných údajov na základe požiadavky používateľa a vyhľadaných výsledkov vyhľadávania, čo umožňuje modelu lepšie pochopiť požiadavky a vygenerovať odpoveď zodpovedajúcu zadaným kritériám. Ďalšia zložka kombinuje rôzne metódy vyhľadávania a spracováva dokumenty tak, aby obsahovali len základné údaje potrebné na vygenerovanie odpovede. Na generovanie textu systém komunikuje s externým rozhraním pomocou špeciálnej triedy, ktorá zabezpečuje opätovné spracovanie dotazov v prípade dočasného preťaženia a používa dva varianty modelov - ľahší a robustnejší - na dosiahnutie optimálnej rýchlosti a kvality výsledkov. Na konci sa získané odpovede kontrolujú pomocou funkcií, ktoré vyhodnocujú ich úplnosť a logickú zhodu s pôvodným dotazom.

\subsection*{Dynamické tvorenie promptov a spracovanie dokumentov}

Funkcia \texttt{build\_dynamic\_prompt} je kľúčovou zložkou systému, pretože generuje nápovedu pre jazykový model spojením výsledkov vyhľadávania Elasticsearch do jedného súvislého textového reťazca. Účelom tejto výzvy je dať modelu pokyn, aby interpretoval používateľovu požiadavku, identifikoval ďalšie požiadavky a poskytol odpoveď, ktorá obsahuje odporúčania na lieky vrátane ich názvov, stručného opisu a - ak je to potrebné - informácie o dávkovaní alebo čase užívania.

Okrem toho systém využíva komponent, ktorý rozdeľuje dlhé texty na zvládnuteľné časti. To je dôležité najmä vtedy, ak generovaný text prekročí limit tokenov podporovaný generatívnym modelom. Toto delenie zabezpečuje, že každý segment textu je vhodný na spracovanie, čo zvyšuje celkovú efektívnosť a rýchlosť odozvy.

Nasledujúci príklad kódu ukazuje implementáciu funkcie spolu s komentármi, ktoré vysvetľujú, ako sa vytvára prompt na základe používateľského dotazu a výsledkov vyhľadávania:

\begin{minted}{python}
def build_dynamic_prompt(query: str, documents: list) -> str:
    # Spojí dokumenty do jedného textu
    documents_str = "\n".join(documents)
    # Vytvorí prompt, ktorý obsahuje otázku a inštrukcie pre generovanie odpovede
    prompt = (
        f"Otázka: '{query}'.\n"
        "Na základe nasledujúcich informácií o liekoch:\n"
        f"{documents_str}\n\n"
        "Analyzuj uvedenú otázku a zisti, či obsahuje dodatočné požiadavky okrem odporúčania liekov. "
        "Ak áno, v odpovedi najprv uveď odporúčané lieky – pre každý liek uveď jeho názov, stručné vysvetlenie a, ak je to relevantné, "
        "odporúčané dávkovanie alebo čas užívania, a potom v ďalšej časti poskytnú odpoveď na dodatočné požiadavky. "
        "Ak dodatočné požiadavky nie sú prítomné, uveď len odporúčanie liekov. "
        "Odpovedaj priamo a ľudským, priateľským tónom v číslovanom zozname, bez zbytočných úvodných fráz. "
        "Odpoveď musí byť v slovenčine. "
        "Prosím, odpovedaj v priateľskom, zdvorilom a profesionálnom tóne, bez akýchkoľvek agresívnych či drzých výrazov."
    )
    return prompt
\end{minted}



Na základe kódu funkcia najprv vytvorí reťazec obsahujúci úryvky textu z dokumentov, ktoré sa potom vložia do podrobne definovanej nápovedy. Táto nápoveda slúži ako vstup pre rozhranie API Mistral, ktoré na základe poskytnutého kontextu vygeneruje odpoveď. Ďalej nasleduje integrácia logiky, ktorá zabezpečí, že ak je text príliš dlhý, rozdelí sa na menšie segmenty, čím sa optimalizuje jeho spracovanie a vyhodnotenie.

Celkovým cieľom tejto modulárnej implementácie je zabezpečiť, aby systém flexibilne reagoval na rôzne typy používateľských dotazov a generoval odpovede, ktoré sú nielen presné a úplné, ale aj logicky konzistentné.


\section{Kontextová analýza, interpretácia a klasifikácia dopytov}

Okrem jednoduchej extrakcie kľúčových slov systém vykonáva komplexnú kontextovú analýzu na základe vstupných dotazov.  Pomocou viacvrstvového prístupu sa v prvej vrstve skúma gramatická štruktúra a v druhej vrstve sa hľadajú vzory implicitného významu.  Táto technika umožňuje identifikovať aj komplikované otázky, ktoré môžu obsahovať niekoľko čiastkových dotazov alebo skrytých hľadaní.  Výsledkom je rozšírený kontextový profil, ktorý sa potom využíva na optimalizáciu výziev generatívneho modelu.  Táto metóda uľahčuje pochopenie kontextu a vytvára základ pre presnejšiu interpretáciu otázky.

Po tejto dôkladnejšej analýze sa systém sústredí na kategorizáciu dopytov, aby zistil, či ide o úplne originálnu vyhľadávaciu požiadavku alebo o vylepšenie už existujúcej odpovede.  Na tento účel je vytvorená funkcia, ktorá po rozbore dôležitých výrazov vo vstupnom texte, ako napríklad „môžete mi o tom povedať viac?“ alebo „čo ešte viete o...“, priradí dopyt do jednej z kategórií.

 Po určení, že dotaz je čerstvý, systém vyhľadá vo svojej databáze relevantné dokumenty (pomocou kombinácie vektorového a textového vyhľadávania).  Zhromažďuje sa história konverzácie a spresňujú sa len informácie, ktoré rozširujú prvú odpoveď, ak klasifikátor určí, že používateľ objasňuje alebo rozširuje už položenú otázku.
.

Na základe výsledkov z databázy (príp. kontextu z histórie interakcií) sa potom dynamicky vytvára prompt, ktorý kombinuje pôvodnú otázku používateľa s nájdenými dokumentmi a akýmikoľvek dôležitými údajmi (napríklad špecifické požiadavky, preferencie, anamnéza a pod.). Tým sa zabezpečí, že generatívny model má k dispozícii všetok dostupný kontext, čo zvyšuje presnosť a relevantnosť konečnej odpovede.


\section{Integrácia s externými službami a optimalizácia komunikácie}

Pre zabezpečenie spoľahlivosti a rýchleho spracovania dotazov boli do systému implementované viaceré opatrenia. Trieda \textit{\seqsplit{CustomMistralLLM}} disponuje vstavaným mechanizmom opakovania požiadaviek, ktorý zaručuje, že aj pri dočasnom preťažení API nedôjde k prerušeniu komunikácie. Systém tiež intenzívne využíva knižnicu \textit{\seqsplit{logging}} na zapisovanie kľúčových informácií o spracovaní dotazov, generovaných odpovediach a prípadných chybách, čo výrazne uľahčuje monitorovanie výkonu a rýchle odhaľovanie problémov. Ďalšou integráciou je spojenie s ElasticsearchStore a HuggingFaceEmbeddings, ktoré umožňuje efektívne a presné vyhľadávanie dokumentov v reálnom čase, čím sa zvyšuje kvalita získaných informácií. Okrem toho sú v systéme implementované funkcie na klasifikáciu dopytov (\textit{\seqsplit{classify\_query}}), validáciu odpovedí (\textit{\seqsplit{evaluate\_complete\_answer}} a \textit{\seqsplit{validate\_answer\_logic}}) a spracovanie dlhodobej pamäte prostredníctvom triedy \texttt{ConversationalAgent}, čo umožňuje dynamické získavanie a uchovávanie doplňujúcich informácií o používateľovi (napríklad vek, anamnézu a informáciu o predpise).





\chapter{Používateľské rozhranie a interaktívna komunikácia}

Teoretický opis webovej aplikácie, ktorá slúži ako hlavný prostriedok komunikácie medzi odporúčacím systémom a používateľom, je obsiahnutý v tejto kapitole.  Je veľmi dôležité, aby interakcia systému v prostredí zdravotnej starostlivosti bola jednoduchá, zrozumiteľná a prispôsobená rôznym požiadavkám používateľov.  Vďaka webovej aplikácii je systém široko prístupný na osobných počítačoch, tabletoch a mobilných zariadeniach bez toho, aby bolo potrebné inštalovať akýkoľvek softvér.  Domovská stránka aplikácie poskytuje používateľovi stručný prehľad funkcií systému a podrobne opisuje výhody jeho používania. 


\section{Základné usporiadanie a orientácia v rozhraní}

Je nevyhnutné zabezpečiť rýchlu orientáciu používateľa na stránke.  Webová stránka obsahuje jasné pokyny, ako vstúpiť do interaktívnej komunikácie, ako aj stručný prehľad služieb poskytovaných systémom.  Okrem informačnej časti sa dôraz kladie na jednoznačnú prezentáciu navigačných prvkov, ktoré uľahčujú bezproblémový prístup k primárnym oblastiam vrátane sekcie chatu, kontaktných údajov a podrobností o projekte.  Používateľ môže ľahko prejsť štruktúrou rozhrania a dostať sa do oblasti, kde môže priamo komunikovať so systémom. 
\FloatBarrier
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{AllPage.png}
    \caption{Príklad navigácie na hlavnej stránke.}
    \label{fig:vectorization}
\end{figure}
\FloatBarrier
Ďalším kľúčovým prvkom je optimalizácia pre mobilné zariadenia, ktorá zaručuje, že sa dizajn prispôsobí veľkosti obrazovky a ponúkne konzistentné prostredie na všetkých zariadeniach.



\section{Konverzačné prostredie a spôsob interakcie}

Hlavným komunikačným predpokladom aplikácie je jej konverzačné rozhranie, ktoré umožňuje používateľom klásť otázky v bežnom jazyku a dostávať rýchle odpovede.  Táto metóda umožňuje flexibilnú a plynulú komunikáciu a odstraňuje potrebu pevne stanovených formátov.

Hoci systém ukladá celú históriu komunikácie na jednom mieste, používateľ môže iniciovať nové konverzácie alebo pokračovať v existujúcich.  Táto história zaručuje, že systém má k dispozícii kontext, ktorý zvyšuje kvalitu následných odpovedí a zároveň umožňuje návrat k predchádzajúcim odpovediam.

V skutočnosti to znamená, že ak má používateľ dotaz týkajúci sa určitého lieku, systém sleduje všetky predchádzajúce dotazy a odpovede, čo umožňuje doplnenie informácií alebo objasnenie dotazov bez vymazania kontextu.  Táto metóda funguje obzvlášť dobre, keď je potrebné rýchle rozhodnutie, napríklad v naliehavých lekárskych prípadoch.
\FloatBarrier
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1.1\textwidth]{Ex.png}
    \caption{Príklad komunikácie prostredníctvom webového rozhrania.}
    \label{fig:vectorization}
\end{figure}
\FloatBarrier

\section{Bezpečnosť a ochrana údajov}

Pri návrhu webového rozhrania je nutné venovať osobitnú pozornosť bezpečnosti a ochrane údajov. Aplikácia implementuje moderné bezpečnostné opatrenia, ktoré zabezpečujú ochranu citlivých informácií a overenie prístupu používateľov. Používateľské údaje, vrátane histórie konverzácií, sú uložené v zabezpečenej databáze, pričom prenos informácií prebieha cez šifrované spojenie. Takéto opatrenia znižujú riziko neoprávneného prístupu a zabezpečujú dôvernosť údajov, čo je obzvlášť dôležité v prostredí zdravotníctva.


\section{Možnosti rozšírenia}

Pri navrhovaní webového rozhrania sa zohľadňoval potenciál budúceho vývoja a prispôsobovania sa meniacim sa požiadavkám trhu.  Vďaka modulárnemu charakteru systému je pridávanie nových funkcií a integrácia nových technológií jednoduchá.  V budúcnosti sa napríklad odporúčania môžu prispôsobiť konkrétnym potrebám implementáciou personalizácie na základe preferencií a histórie používateľa.  Do programu možno pridať aj nástroje vizuálnej analýzy, ktoré zobrazujú tabuľky a grafy a ponúkajú informácie o interakciách s liekmi a spracovaných údajoch.\\
Ďalším smerom rozvoja je integrácia ďalších jazykových verzií, čo by umožnilo využitie systému pre medzinárodné publikum. Taktiež je možné uvažovať o prepojení s inými zdravotníckymi IT systémami, čím by sa zlepšila integrácia dát a zabezpečila komplexná analýza zdravotného stavu používateľov. Takéto rozšírenia sú dôležité najmä v dynamickom prostredí digitálneho zdravotníctva, kde je potrebné reagovať na rýchlo meniace sa požiadavky a technologické trendy.

\section{Integrácia s inými systémami a interoperability}

Aplikácia môže komunikovať s inými platformami vrátane databáz pre lekárske odporúčania alebo elektronické zdravotné záznamy.  Kombináciou údajov z viacerých zdrojov môže vzniknúť synergický efekt, ktorý ponúka ucelenejší pohľad na zdravotný stav používateľa.  Takáto integrácia nielenže zvyšuje presnosť odpovedí, ale aj zefektívňuje prácu lekárskych odborníkov.

 V dôsledku toho je systém založený na myšlienke otvorených rozhraní, ktoré zabezpečujú jednoduchú integráciu a prenos údajov medzi rôznymi aplikáciami.  To podporuje prispôsobivosť a umožňuje priebežné vylepšovanie funkčnosti programu bez toho, aby bolo potrebné výrazne upravovať základný systém.




Používateľ a inteligentný odporúčací systém sú prepojení predovšetkým prostredníctvom webového rozhrania a interaktívnej komunikácie.  Bolo zahrnuté všetko od základného rozvrhnutia a navigácie až po konverzačný spôsob zapojenia, bezpečnostné opatrenia a možnosti budúceho vývoja.  Základom celej stratégie je zaručenie bezpečnosti údajov, prispôsobivosti a jednoduchosti používania - to všetko je rozhodujúce pre úspešné nasadenie systému v oblasti digitálneho zdravia.  Výsledné rozhranie nielen uľahčuje získavanie informácií, ale umožňuje aj budúci rast a modifikáciu podľa vyvíjajúcich sa potrieb.





\chapter{Implementácia systému}

Táto kapitola opisuje praktickú implementáciu systému so zameraním na inštaláciu a konfiguráciu vývojového prostredia a integráciu externých rozhraní API. Implementácia je rozdelená do niekoľkých logických častí, ktoré zabezpečujú, že všetky komponenty spolupracujú bez problémov a poskytujú požadovanú funkcionalitu.

\section{Nastavenie a konfigurácia}

Implementácia sa začína vytvorením vhodného vývojového prostredia a konfiguráciou všetkých potrebných komponentov. Backend je vyvíjaný v Pythone, jazyku, ktorý podľa Oliphanta \cite{1} poskytuje bohatý ekosystém knižníc pre strojové učenie, analýzu dát a vedecké výpočty. Na začiatku sa vytvorí virtuálne prostredie, kde sú nainštalované všetky potrebné balíky, aby sa zabezpečila izolácia a konzistentnosť prostredia.

\textbf{Konfigurácia a predspracovanie údajov:}  
Elasticsearch je nainštalovaný a nakonfigurovaný na ukladanie textových dát aj vektorových embeddings. Farmaceutické údaje – vrátane podrobných popisov liekov, ich indikácií, vedľajších účinkov a interakcií – sa zbierajú, čistia a normalizujú. Proces predspracovania zahŕňa čistenie textu, tokenizáciu a normalizáciu údajov, čo zlepšuje kvalitu indexovaných dát. Tieto operácie sú kľúčové pre zabezpečenie presného a robustného vyhľadávania, ako uvádza Manning et al. \cite{2}.

Ďalej sú do konfigurácie zahrnuté aj front-endové technológie. Na tvorbu užívateľského rozhrania sa využíva React, ktorý umožňuje komponentovo orientovaný prístup a opätovné využitie UI komponentov. Pre rýchle a flexibilné štýlovanie sa používa Tailwind CSS, ktorý zjednodušuje vývoj vďaka svojmu utility-first prístupu. Vývojové prostredie je spravované pomocou Node.js a balíkovacích nástrojov ako npm či yarn, čo uľahčuje správu závislostí a aktualizácií.

\section{Integrácia API}

Integrácia s externými API je kľúčová pre využitie pokročilých jazykových modelov, ktoré umožňujú generovanie kvalitných odpovedí na základe prirodzeného jazyka. V systéme je použitá Mistral API, ktorá poskytuje prístup k moderným NLP modelom.

\textbf{Definícia a význam API:}  
API (Application Programming Interface) je rozhranie, ktoré umožňuje rôznym softvérovým komponentom vzájomne komunikovať a zdieľať funkcionalitu. V tomto systéme API umožňuje bezpečné odosielanie požiadaviek na generovanie textu, pričom sú použité špecifické endpointy a autentifikačné kľúče. Bezpečné uloženie týchto API kľúčov je nevyhnutné na zabránenie neoprávneného prístupu a na zachovanie integrity celého systému.

\textbf{Postup integrácie:}  
Najprv sa zabezpečí nastavenie autentifikácie, kde sú API kľúče a endpointy bezpečne uložené (napríklad v konfiguračnom súbore) a následne použité pri odosielaní požiadaviek, čo zaručuje, že iba autorizované aplikácie môžu pristupovať k citlivej funkcionalite. Ďalej sa pomocou knižnice \texttt{requests} odosielajú HTTP požiadavky na Mistral API. Každá požiadavka obsahuje potrebné hlavičky, ako sú Authorization a Content-Type, a štruktúrované dáta vo forme JSON. Po prijatí odpovede systém vykoná jej validáciu a extrakciu relevantných informácií. Ak dôjde k chybám, napríklad pri prekročení časového limitu alebo limitu požiadaviek, je implementovaný mechanizmus opätovného pokusu s oneskorením, čím sa zvyšuje robustnosť komunikácie s API. Pre zvýšenie efektivity a rýchlosti je využité aj asynchrónne spracovanie, ktoré umožňuje súbežné spracovanie viacerých požiadaviek bez výrazných oneskorení.

Tieto praktické postupy integrácie API, vrátane bezpečnostných opatrení a optimalizácie komunikácie, boli ďalej popísané v práci Smith a Doe \cite{11}, čo poskytuje cenné usmernenia pre tvorbu spoľahlivých systémov. Ako uvádzajú Devlin et al. \cite{8} a Wei et al. \cite{4}, správne nastavené a optimalizované API integrácie sú základom pre efektívne využitie moderných NLP modelov, čím sa zabezpečuje hladká a spoľahlivá komunikácia, ktorá je kritická pre generovanie kvalitných odpovedí a celkovú funkčnosť systému.

% ==================== NOVÁ DOPLŇUJÚCA ČASŤ ====================
\medskip

Spolu s už opísanými postupmi integrácie API zahŕňa implementácia niekoľko kľúčových bezpečnostných opatrení, ktoré zabezpečujú celkovú stabilitu a účinnosť systému.   Kód zisťuje prípady, keď rozhranie API Mistral vráti protokol HTTP 429 (prekročený limit rýchlosti), pomocou logiky spracovania chýb.   Niekedy sa po malom počkaní spustí mechanizmus opakovania, ktorý automaticky odošle požiadavku znova.   Táto technika zaručuje, že dočasné pretečenie API nenaruší celkovú funkčnosť aplikácie.


Každá interakcia s rozhraním API sa tiež starostlivo zaznamenáva.   Každý pokus o požiadavku vrátane chybových správ sa zaznamenáva pomocou knižnice \texttt{logging}.   Vývojári môžu týmto spôsobom rýchlo identifikovať a preskúmať akékoľvek problémy, čo urýchľuje ladenie a zlepšuje spoľahlivosť systému.

 Okrem toho je integrácia API prispôsobiteľná; faktory, ktoré riadia vytváranie textu, vrátane maximálneho množstva tokenov a teploty, možno meniť podľa konkrétnych požiadaviek každej požiadavky.  Vďaka tejto flexibilite možno vyvážiť kvalitu vytvorených odpovedí a rýchlosť spracovania. 

Systém podporuje aj asynchrónne spracovanie požiadaviek, čo umožňuje paralelné odosielanie viacerých požiadaviek a znižuje latenciu celej aplikácie. Tento prístup je výhodný v situáciách, keď je potrebné spracovať vysoký počet dopytov súčasne, čím sa zvyšuje celková efektivita a škálovateľnosť systému.


\section{Bezpečnosť a monitorovanie}

Pri implementácii systému sa venuje veľká pozornosť bezpečnosti a ochrane údajov. Po prvé, konfiguračné súbory obsahujúce citlivé informácie vrátane kľúčov API potrebných na prístup k externým službám sa načítavajú pomocou bezpečných techník. Systém zabraňuje fungovaniu bez požadovaného overenia tým, že kontroluje prítomnosť kľúča API a v prípade jeho chýbania vyhlási chybu. Na komunikáciu s externými API, ako je napríklad Mistral, sa používa protokol HTTPS, ktorý zaručuje, že údaje sú zabezpečené a chránené pred zachytením škodlivými subjektmi.

Súčasťou kódu je aj silný systém spracovania chýb. Okrem zlepšenia stability systému pomáha implementácia mechanizmu opakovania s oneskorením aj pri zmarení prípadných útokov DoS. Elasticsearch podporuje lokálne aj cloudové formy pripojenia. Na zvýšenie bezpečnosti údajov uchovávaných v databáze sa v cloudovom režime používajú metódy overovania využívajúce používateľské meno a heslo.

Systém tiež aktívne zaznamenáva všetky pozoruhodné udalosti a chyby, čo umožňuje rýchlu identifikáciu a preskúmanie akýchkoľvek nezrovnalostí alebo pokusov o nezákonný prístup. Táto metóda uľahčuje bezpečnostné audity a zabezpečuje vysokú úroveň ochrany a spoľahlivosti pri spracovaní citlivých údajov kombináciou prísnej kontroly, riadenia chýb a zabezpečeného prenosu aj ukladania dát.

\section{Postup spracovania požiadavky}

Nižšie je uvedená tabuľka, ktorá znázorňuje postup spracovania požiadavky od používateľa až po vrátenie odpovede:


\FloatBarrier
\begin{table}[htbp]
\centering
\caption{Postup spracovania požiadavky od používateľa}
\begin{tabular}{|l|p{9cm}|}
\hline
\textbf{Krok} & \textbf{Popis} \\ \hline
Odoslanie požiadavky & Používateľ zadá otázku cez užívateľské rozhranie. \\ \hline
Vyhľadávanie dokumentov & Na základe otázky systém vyhľadá relevantné dokumenty pomocou ElasticsearchStore, využívajúceho vektorové aj tradičné textové vyhľadávanie. \\ \hline
Generovanie promptu & Funkcia \texttt{build\_dynamic\_prompt} vytvorí prompt kombináciou používateľskej otázky a výsledkov vyhľadávania. \\ \hline
Odoslanie požiadavky na API & Trieda \texttt{CustomMistralLLM} odošle HTTP požiadavku s vytvoreným promptom na Mistral API. \\ \hline
Spracovanie odpovede & Mistral API vráti generovanú odpoveď, ktorá je následne validovaná a vyhodnotená pomocou funkcií \texttt{evaluate\_complete\_answer} a \texttt{validate\_answer\_logic}. \\ \hline
Návrat výsledku & Spracovaná a overená odpoveď sa vráti používateľovi cez užívateľské rozhranie. \\ \hline
\end{tabular}
\end{table}
\FloatBarrier




\chapter{Vyhodnotenie a testovanie}


Cieľom hodnotenia a testovania systému je zabezpečiť, aby generované odpovede logicky a úplne spĺňali požadované kritériá. Proces testovania a hodnotenia prebieha v niekoľkých fázach pomocou špeciálne navrhnutých funkcií, ktoré automatizujú analýzu odpovedí pomocou jazykového mo-
delu (LLM). Vysvetlenie jednotlivých krokov tohto procesu:

\section{Automatizované hodnotenie odpovedí}

Funkcia \texttt{evaluate\_complete\_answer} je zodpovedná za automatické vyhodnotenie kvality generovanej odpovede. Do funkcie sa odovzdáva pôvodná otázka spolu s vygenerovanou odpoveďou. Následne funkcia zostaví špecifický hodnotiaci prompt, v ktorom sú definované kritériá, podľa ktorých má odpoveď byť posúdená. Medzi tieto kritériá patrí, že odpoveď musí obsahovať odporúčania liekov vrátane ich názvov a stručného vysvetlenia, pričom ak boli v otázke požadované dodatočné informácie, ako napríklad dávkovanie alebo čas užívania, musia byť tieto informácie zahrnuté. Okrem toho, ak otázka obsahovala dodatočné požiadavky, odpoveď musí obsahovať aj samostatnú časť, ktorá tieto požiadavky rieši. Na základe tohto promptu je jazykový model vyzvaný, aby vrátil hodnotenie odpovede na stupnici od 0 do 10, kde 10 znamená, že odpoveď je úplne logická a obsahuje všetky požadované informácie.
\FloatBarrier
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{Evaluation.png}
    \caption{Príklad výsledku hodnotenia systému Mistral.}
    \label{fig:vectorization}
\end{figure}
\FloatBarrier

\section{Validácia logickej konzistencie}


Funkcia \texttt{validate\_answer\_logic} slúži na to, aby vygenerovaná odpoveď presne zodpovedala položenému dotazu a obsahovala všetky dôležité informácie. Najprv na základe pôvodnej otázky a vygenerovanej odpovede vytvorí dodatočný prompt, ktorý pýta jazykový model, aby preveril, či odpoveď logicky zodpovedá dotazu a či sú v nej zahrnuté všetky požadované detaily. Ak zistí, že niektoré informácie (napríklad údaje o dávkovaní alebo čase užívania) chýbajú, model vytvorí opravenú verziu odpovede. Výsledkom je konečná odpoveď, ktorá je logická a kompletná.
Nižšie je príklad promptu, ktorý sa používa na validáciu logickej konzistencie odpovede:

\begin{minted}{python}
validation_prompt = (
    f"Otázka: '{query}'\n"
    f"Odpoveď: '{answer}'\n\n"
    "Analyzuj prosím túto odpoveď. Ak odpoveď neobsahuje všetky dodatočné informácie, na ktoré sa pýtal používateľ, "
    "alebo ak odporúčania liekov nie sú úplné (napr. chýba dávkovanie alebo čas užívania, ak boli takéto požiadavky v otázke), "
    "vytvor opravenú odpoveď, ktorá je logicky konzistentná s otázkou. "
    "Odpovedz v slovenčine a iba čistou, konečnou odpoveďou bez ďalších komentárov."
)
\end{minted}

Tento prompt zabezpečí, že model nielen analyzuje pôvodnú odpoveď, ale zároveň ju doplní o chýbajúce informácie, ak je to potrebné. Takto sa zvyšuje kvalita výsledného textu a zaručuje sa, že používateľ dostane odpoveď, ktorá zodpovedá jeho pôvodnej otázke, je logicky konzistentná a obsahuje všetky kľúčové detaily.


\section{Testovanie celkového procesu spracovania dotazu}

Hlavná funkcia integruje všetky vyššie uvedené komponenty do jedného súvislého pracovného postupu:
\begin{enumerate}
    \item \textbf{Vyhľadávanie relevantných dokumentov:} Na základe zadaného dotazu systém vykonáva vyhľadávanie pomocou vektorového aj tradičného textového vyhľadávania (prostredníctvom Elasticsearch).
    \item \textbf{Generovanie odpovedí:} Pre každý typ vyhľadávania sa zostaví dynamický prompt , ktorý inštruuje model na generovanie odpovedí s požadovanou štruktúrou (odporúčania liekov a prípadne dodatočné informácie). Odpovede sú generované dvoma variantmi modelu ( Mistral Small a Mistral Large).
    \item \textbf{Hodnotenie kvality:} Pre každú vygenerovanú odpoveď sa spustia funkcie, ktoré vyhodnotia, či odpovede spĺňajú kritériá kvality a logickej konzistencie, a vytvoria číselné hodnotenie.
    \item \textbf{Výber najlepšej odpovede:} Na základe získaných hodnotení sa porovnajú výsledky a vyberie sa odpoveď s najvyšším skóre. Ďalej je vykonaná dodatočná validácia logiky, aby sa zabezpečilo, že konečná odpoveď je komplexná a presná.
    \item \textbf{Finálne spracovanie a odoslanie výsledku:} Nakoniec je vybraná odpoveď dodatočne upravená (napríklad preložená alebo spracovaná tak, aby zachovala špecifické formátovanie) a následne odoslaná späť ako konečný výsledok spolu s informáciami o použitom modeli a hodnotiacim skóre.
\end{enumerate}

Celý tento proces je logicky prepojený a monitorovaný pomocou logovacích mechanizmov, čo umožňuje priebežné sledovanie a ladenie systému. Výsledkom testovania a hodnotenia je robustný systém, ktorý nielen generuje odpovede na základe zadaných dotazov, ale aj systematicky kontroluje a optimalizuje ich kvalitu podľa definovaných kritérií.




\newpage

\chapter{Záver a budúci vývoj}
\label{chap:conclusion_future}

\section{Budúca práca a vylepšenia}

Riešenie už teraz dokazuje, že dokáže efektívne spracúvať komplikované dotazy a ponúkať kvalitné návrhy liekov, budúca práca a zlepšenia predstavujú kľúčovú cestu pre ďalší rozvoj systému. Metódy, ktorými možno systém ďalej zlepšovať, zvyšovať jeho funkčnosť a ponúkať ešte väčšiu flexibilitu a odolnosť, sú podrobnejšie opísané v tejto kapitole. Aby bolo možné ešte efektívnejšie využívať umelú inteligenciu v zdravotníctve, budúci vývoj sa sústredí na optimalizáciu výkonu, zlepšenie analytických schopností, prispôsobenie sa meniacim sa požiadavkám trhu a začlenenie nových technológií.

Optimalizácia výkonu a škálovateľnosti je jedným z hlavných cieľov ďalších projektov. Je nevyhnutné zabezpečiť, aby systém dokázal zvládnuť veľké množstvo požiadaviek bez toho, aby sa znížil výkon spracovania pri zvyšovaní objemu údajov a počtu používateľov. Plánuje sa nasadenie techník vyrovnávania záťaže a cloudových technológií, ktoré umožnia systému dynamicky meniť kapacitu v závislosti od aktuálnych požiadaviek. Na automatizáciu správy a škálovania kontajnerov v distribuovanom prostredí sa vývojári sústredia na zefektívnenie algoritmov, implementáciu techník ukladania do vyrovnávacej pamäte a využitie súčasných orchestračných technológií. Okrem toho tieto technológie zlepšia robustnosť a redundanciu, čím sa zníži vplyv možných porúch na koncových zákazníkov.

Ďalšou možnosťou rozvoja je rozšírenie funkčných schopností systému. Okrem vytvárania základných odpovedí budú implementované moduly na sofistikovanú analýzu údajov, ktoré dokážu dôkladnejšie vyhodnocovať a predpovedať vzory vo farmaceutických údajoch. Kombinácia strojového učenia s historickými údajmi umožní vytvárať predikčné modely, návrhy na mieru a trendy, ktoré možno využiť na zlepšenie výsledkov liečby. Okrem toho môže táto analýza vytvoriť základ pre interakciu so systémami IT v oblasti zdravotníctva, automatizovať zber, aktualizáciu a validáciu údajov a zároveň zaručiť včasné a kvalitné údaje.

Jednou z hlavných priorít bude posilnenie systémov monitorovania a spätnej väzby. Systém plánuje zahrnúť sofistikované analytické funkcie na automatickú kontrolu kvality vytvorených odpovedí, analýzu protokolov a sledovanie správania používateľov. Získanie vstupných údajov v reálnom čase umožní okamžite zistiť nedostatky a rýchlo ich odstrániť. Takáto prispôsobiteľná metóda zaručí, že systém sa bude neustále vyvíjať a prispôsobovať trendom a požiadavkám zdravotníctva.

Zlepšenie súčasných algoritmov a rozšírenie integrácie nových generatívnych modelov sú kľúčovými prvkami budúceho úsilia. Pravidelné monitorovanie a testovanie nových modelov a stratégií je vzhľadom na rýchly pokrok v oblasti umelej inteligencie a NLP kľúčové. Použije sa modulárna architektúra, ktorá umožní jednoduché pridávanie a testovanie nových častí bez výrazného narušenia súčasnej infraštruktúry. V období neustáleho technologického pokroku by takáto flexibilná architektúra umožnila rýchlu integráciu inovácií, čím by riešenie zostalo aktuálne a konkurencieschopné.

Zabezpečenie priebežnej automatizácie a integrácie procesu testovania a nasadzovania bude poslednou kľúčovou fázou. Okrem toho, že umožní rýchle nasadenie nových funkcií, plne integrovaný CI/CD pipeline by tiež výrazne znížil možnosť chýb spôsobených rozdielmi medzi vývojovým a produkčným prostredím. Vysoká spoľahlivosť a stabilita systému sa zabezpečí automatizáciou testovania, nasadzovania a monitorovania, aby bolo možné okamžite reagovať na vstupy používateľov. Budúce úsilie bude v konečnom dôsledku prínosom nielen pre technologický pokrok systému, ale aj pre jeho schopnosť rýchlo sa prispôsobovať meniacim sa potrebám trhu a zvyšovať úroveň poskytovanej zdravotnej starostlivosti.

\section{Rozširovanie do príbuzných domén}

Hoci sa aktuálne riešenie zameriava najmä na farmaceutickú oblasť, podobný koncept je možné aplikovať aj v príbuzných doménach. Napríklad, v nutričnom poradenstve by systém mohol integrovať databázu informácií o stravovacích plánoch a interakciách medzi jedlami a liekmi. Rovnako v diagnostike by mohol model vyhľadávať zoznam symptómov v lekárskych publikáciách a poskytovať relevantné odporúčania na vyšetrenia.

Tieto rozšírenia si budú vyžadovať prispôsobenie dátovej štruktúry, aby systém dokázal efektívne prepájať farmaceutické informácie s inými typmi dát. Napríklad pri nutričných odporúčaniach je dôležité špecifikovať alergény, kalorické hodnoty či interakcie s liekmi. V týchto prípadoch sa opäť uplatní semantické vyhľadávanie a vektorové reprezentácie, ktoré dokážu prepojiť rôzne zdroje informácií podľa významu.

\section{Zavedenie multi-language podpory}

Pridanie ďalšej jazykovej podpory do systému je logickým ďalším krokom vo vývoji.  Hoci sa projekt v súčasnosti primárne zameriava na slovenčinu (resp. češtinu) alebo angličtinu, rastúci dopyt zo strany medzinárodných organizácií si môže vyžiadať inštaláciu viacjazyčných a plynulých prekladových funkcií.

Na tento účel sa môžu použiť napríklad viacjazyčné vnorenia, ktoré dokážu poskytnúť podobné vektorové reprezentácie pre niekoľko jazykov (napríklad LaBSE od spoločnosti Google).  Ďalšou možnosťou je automatický promptný preklad.  Pred odoslaním do modelu na spracovanie by sa výzva preložila. Potom by sa preložila aj vytvorená odpoveď.  Zachovanie priebehu diskusie závisí od presnosti a rýchlosti prekladov.  Pri práci s rôznymi jazykovými oblasťami by mohlo byť dôležité zahrnúť jazykovo špecifické databázy znalostí, ako sú miestne registrácie liekov, príbalové letáky a platné zákony.

Z technického hľadiska treba zároveň dbať na správne kódovanie (napríklad Unicode), normalizáciu textu či rozdielnu tokenizáciu podľa konkrétneho jazyka. Týmto spôsobom sa môže systém rozšíriť na viacero trhov a užívateľských skupín, čím získa medzinárodný dosah.


\section{Zhrnutie dosiahnutých výsledkov}

Táto práca predstavuje implementáciu systému odporúčaní, ktorý využíva moderné metódy spracovania prirodzeného jazyka a techniky vektorového vyhľadávania na poskytovanie presných a relevantných informácií o liekoch. Systém umožňuje používateľom klásť dotazy v prirodzenom jazyku a na základe týchto dotazov generuje obsahovo bohaté odpovede, ktoré obsahujú odporúčania liekov vrátane ich základných informácií, ako sú názov, stručné vysvetlenie a prípadne aj informácie o dávkovaní či čase užívania.

\section{Hlavné prínosy projektu}

Vyvinuté riešenie demonštruje praktickú implementáciu niekoľkých kľúčových technológií. Systém efektívne spracováva rozsiahle a heterogénne farmaceutické údaje prostredníctvom ich systematického indexovania v Elasticsearch. Využitie techník predspracovania, ako je čistenie, tokenizácia a normalizácia, zaručuje vysokú kvalitu vstupných dát a umožňuje ich robustné vyhľadávanie. Dynamické generovanie promptov pomocou funkcie \texttt{build\_dynamic\_prompt} umožňuje modelu získať dostatočný kontext z relevantných dokumentov, čo výrazne zvyšuje presnosť generovaných odpovedí. Integrácia s Mistral API umožňuje generovať odpovede na základe pokročilých generatívnych jazykových modelov, ktoré dokážu adaptívne reagovať na rôzne typy dopytov a poskytovať obsahovo bohaté a logicky konzistentné výsledky. Použitie techník vektorového vyhľadávania umožňuje získavať relevantné dokumenty aj v prípade, že formulácia dotazu nie je úplne zhodná s textom uloženým v databáze, čím sa zvyšuje celková presnosť vyhľadávania. Implementácia mechanizmov na opakovanie požiadaviek a monitorovanie chýb zabezpečuje, že systém je robustný a schopný zvládnuť dočasné výpadky alebo preťaženie externých API. Kontajnerizácia pomocou Dockeru zaručuje konzistenciu prostredia a umožňuje rýchle nasadenie a škálovanie riešenia.

\section{Zhodnotenie implementácie}

Podľa výsledkov testovania dokáže systém spracovať zložité otázky a poskytnúť odpovede, ktoré sú relevantné pre obsah a prispôsobené požiadavkám každého používateľa.  Celkovú kvalitu výstupu ovplyvňujú jednotlivé fázy vrátane vyhľadávania dokumentov, dynamického generovania výziev, tvorby textu a overovania.  Účinnosť stratégie bola overená aplikáciou súčasných technológií NLP a vektorového vyhľadávania a starostlivé monitorovanie a riadenie chýb podporilo odolnosť a prispôsobivosť celého riešenia.

Implementované riešenie preukázalo, že integrácia generatívnych modelov s technikami vektorového vyhľadávania a starostlivo spracovaných doménových údajov môže výrazne zlepšiť prístup k informáciám o liekoch. Systém je schopný reagovať na dotazy formulované v prirodzenom jazyku a poskytovať presné a kontextovo bohaté odpovede, ktoré sú užitočné pre zdravotníckych pracovníkov aj pacientov. Celková implementácia preukázala, že vybudovaný systém je nielen funkčný, ale aj efektívny pri spracovaní veľkého množstva dát, pričom jeho robustnosť a spoľahlivosť zabezpečuje praktickú využiteľnosť v reálnych podmienkach. Záver projektu potvrdzuje potenciál umelej inteligencie v oblasti zdravotníckych informácií a poskytuje pevný základ pre ďalšie skúmanie a optimalizáciu implementovaných technológií.

\begin{thebibliography}{15}

\bibitem{1}
Oliphant, T. E. (2007). Python for Scientific Computing. \textit{Computing in Science \& Engineering, 9}(3), 10--20.

\bibitem{2}
Manning, C. D., Raghavan, P., \& Schütze, H. (2008). \textit{Introduction to Information Retrieval}. Cambridge University Press.

\bibitem{3}
Wolf, T., Debut, L., Sanh, V., Chaumond, J., et al. (2020). Transformers: State-of-the-Art Natural Language Processing. In \textit{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations} (pp. 38--45).

\bibitem{4}
Wei, J., et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. In \textit{Proceedings of NeurIPS 2022}.

\bibitem{5}
Garcia, M., \& Lee, S. (2019). An Empirical Analysis of Modern Frontend Frameworks: A Case Study on React. \textit{Journal of Web Engineering, 18}(4), 300--320.

\bibitem{6}
Nguyen, T. (2020). Utility-First CSS: A Comparative Study of Tailwind CSS and Traditional Approaches. \textit{International Journal of Web Design and Development, 12}(2), 45--60.

\bibitem{7}
Merk, D. (2014). Docker: Lightweight Linux Containers for Consistent Development and Deployment. \textit{Linux Journal, 239}, 2.

\bibitem{8}
Devlin, J., Chang, M. W., Lee, K., \& Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. \textit{arXiv preprint arXiv:1810.04805}.

\bibitem{9}
Boettiger, C. (2015). An Introduction to Docker for Reproducible Research. \textit{ACM SIGOPS Operating Systems Review, 49}(1), 71--79.

\bibitem{10}
Kumar, A., Patel, R., \& Singh, M. (2020). Performance Evaluation of Containerized Applications. \textit{Journal of Cloud Computing, 9}(1), 45--60.

\bibitem{11}
Smith, J., \& Doe, A. (2019). API Integration in Microservices Architecture. \textit{IEEE Software, 36}(2), 50--56.

\bibitem{12}
Lee, C., Kim, S., \& Park, J. (2021). Advances in Natural Language Processing for Healthcare. \textit{ACM Transactions on Computing for Healthcare, 2}(3), 1--22.

\bibitem{13}
Lewis, P., Perez, E., Piktus, A., Petroni, F., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. \textit{Advances in Neural Information Processing Systems (NeurIPS)}.

\bibitem{14}
Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Yih, W., \& Collins, M. (2020).
Dense Passage Retrieval for Open-Domain Question Answering.
\textit{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, 6769--6781.

\bibitem{15}
Brown, T., Mann, B., Ryder, N., Subbiah, M., et al. (2020). Language Models are Few-Shot Learners.
\textit{Advances in Neural Information Processing Systems (NeurIPS)}, 33, 1877--1901.

\bibitem{16}
Reimers, N., \& Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP).

\end{thebibliography}
